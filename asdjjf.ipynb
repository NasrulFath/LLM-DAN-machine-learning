{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM SEDERHANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\asus\\miniconda3\\lib\\site-packages (0.3.26)\n",
      "Requirement already satisfied: openai in c:\\users\\asus\\miniconda3\\lib\\site-packages (1.90.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\miniconda3\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\miniconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain) (0.3.66)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain) (0.4.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus\\miniconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from openai) (4.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\miniconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain openai matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9824\\2825341156.py:54: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the SalesCorrelation tool to calculate the correlation between discount and sales.\n",
      "Action: SalesCorrelation\n",
      "Action Input: \"diskon dan penjualan\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m0.9111916759223988\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 0.9111916759223988\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Interpretasi AI:\n",
      "Nilai korelasi antara diskon dan jumlah penjualan sebesar 0.9111916759223988 menunjukkan adanya hubungan positif yang kuat antara kedua variabel tersebut. Artinya, semakin besar diskon yang diberikan, maka jumlah penjualan juga cenderung meningkat.\n",
      "\n",
      "Contoh penjelasan yang mudah dimengerti adalah ketika sebuah toko memberikan diskon besar untuk produk tertentu, maka kemungkinan besar jumlah penjualan produk tersebut akan meningkat secara signifikan. Hal ini dapat terjadi karena konsumen cenderung tertarik untuk membeli produk dengan diskon yang menarik. Sebaliknya, jika diskon yang diberikan kecil atau tidak ada, maka jumlah penjualan juga cenderung stagnan atau bahkan menurun.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Buat data penjualan langsung di kode\n",
    "data = {\n",
    "    \"tanggal\": [\n",
    "        \"2025-06-01\", \"2025-06-02\", \"2025-06-03\",\n",
    "        \"2025-06-04\", \"2025-06-05\", \"2025-06-06\"\n",
    "    ],\n",
    "    \"produk\": [\n",
    "        \"Produk A\", \"Produk B\", \"Produk A\",\n",
    "        \"Produk C\", \"Produk B\", \"Produk A\"\n",
    "    ],\n",
    "    \"jumlah_terjual\": [100, 80, 120, 50, 90, 110],\n",
    "    \"diskon_persen\": [10, 5, 15, 0, 10, 20]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"tanggal\"] = pd.to_datetime(df[\"tanggal\"])\n",
    "\n",
    "# Tool untuk hitung korelasi saja\n",
    "def sales_correlation_tool(query: str) -> str:\n",
    "    corr = df[\"diskon_persen\"].corr(df[\"jumlah_terjual\"])\n",
    "    return f\"{corr}\"\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"SalesCorrelation\",\n",
    "        func=sales_correlation_tool,\n",
    "        description=\"Hitung korelasi antara diskon dan jumlah terjual.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Inisialisasi LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Prompt template untuk interpretasi korelasi\n",
    "template = \"\"\"\n",
    "Hasil korelasi antara diskon dan jumlah penjualan adalah {correlation}.\n",
    "Jelaskan arti dari nilai korelasi ini secara singkat, apakah positif atau negatif,\n",
    "dan apa artinya untuk penjualan.\n",
    "Berikan contoh penjelasan yang mudah dimengerti.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"correlation\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Initialize agent dengan tool\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "# 1. Panggil agent untuk hitung korelasi (Action + Observation)\n",
    "correlation_str = agent.run(\"Hitung korelasi diskon dan penjualan.\")\n",
    "\n",
    "# 2. Beri korelasi ke LLMChain untuk interpretasi dan penjelasan\n",
    "response = llm_chain.run(correlation=correlation_str)\n",
    "\n",
    "print(\"Interpretasi AI:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSaya perlu menggunakan SalesDetailedAnalyzer untuk mendapatkan informasi yang spesifik.\n",
      "Action: SalesDetailedAnalyzer\n",
      "Action Input: \"penjualan\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRata-rata pembelian berdasarkan jenis kelamin:\n",
      "gender\n",
      "F    114.0\n",
      "M    116.0\n",
      "\n",
      "Jumlah pembelian per jam:\n",
      "purchase_datetime\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "13    1\n",
      "14    1\n",
      "17    1\n",
      "18    1\n",
      "19    1\n",
      "20    1\n",
      "21    1\n",
      "\n",
      "Jam sibuk: 9:00\n",
      "Jenis kelamin paling aktif di jam sibuk: F\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mSaya perlu melihat lebih detail tentang pola pembelian pada jam 9:00.\n",
      "Action: SalesDetailedAnalyzer\n",
      "Action Input: \"pembelian jam 9:00\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRata-rata pembelian berdasarkan jenis kelamin:\n",
      "gender\n",
      "F    114.0\n",
      "M    116.0\n",
      "\n",
      "Jumlah pembelian per jam:\n",
      "purchase_datetime\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "13    1\n",
      "14    1\n",
      "17    1\n",
      "18    1\n",
      "19    1\n",
      "20    1\n",
      "21    1\n",
      "\n",
      "Jam sibuk: 9:00\n",
      "Jenis kelamin paling aktif di jam sibuk: F\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mSaya sudah memiliki informasi yang cukup untuk menjawab pertanyaan.\n",
      "Final Answer: Rata-rata pembelian berdasarkan jenis kelamin adalah F 114.0 dan M 116.0. Jam sibuk adalah jam 9:00 dengan jenis kelamin paling aktif adalah F.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hasil Analisis dan Saran dari AI:\n",
      "Hasil analisis data menunjukkan bahwa rata-rata pembelian per transaksi untuk pelanggan perempuan adalah 114.0, sedangkan untuk pelanggan laki-laki adalah 116.0. Hal ini menunjukkan bahwa tidak ada perbedaan signifikan dalam jumlah pembelian antara pelanggan perempuan dan laki-laki.\n",
      "\n",
      "Jam sibuk untuk penjualan adalah pada jam 9:00, dan pelanggan perempuan adalah yang paling aktif berbelanja pada jam tersebut. Hal ini menunjukkan bahwa pada jam tersebut, bisnis memiliki potensi untuk meningkatkan penjualan dengan menargetkan promosi khusus untuk pelanggan perempuan.\n",
      "\n",
      "Saran strategis yang relevan berdasarkan hasil analisis ini adalah:\n",
      "1. Meningkatkan promosi pada jam sibuk, terutama untuk pelanggan perempuan. Misalnya, dapat memberikan diskon khusus atau penawaran menarik untuk produk yang sering dibeli oleh pelanggan perempuan.\n",
      "2. Melakukan survei atau studi lebih lanjut untuk memahami preferensi dan kebutuhan pelanggan perempuan, sehingga bisnis dapat menyesuaikan strategi pemasaran dan penjualan untuk menarik lebih banyak pelanggan perempuan.\n",
      "3. Memperhatikan faktor-faktor lain yang mungkin memengaruhi pola pembelian, seperti harga, kualitas produk, atau pelayanan, untuk meningkatkan pengalaman belanja pelanggan dan mendorong pembelian lebih banyak.\n",
      "\n",
      "Dengan menerapkan strategi-strategi ini, diharapkan bisnis dapat meningkatkan penjualan dan memperkuat hubungan dengan pelanggan, terutama pelanggan perempuan yang aktif berbelanja pada jam sibuk.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Contoh data pelanggan\n",
    "data = {\n",
    "    \"customer_id\": [1,2,3,4,5,6,7,8,9,10],\n",
    "    \"gender\": [\"M\", \"F\", \"F\", \"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\"],\n",
    "    \"purchase_datetime\": [\n",
    "        \"2025-06-01 10:00\", \"2025-06-01 11:30\", \"2025-06-02 09:15\",\n",
    "        \"2025-06-02 18:45\", \"2025-06-03 14:00\", \"2025-06-03 20:30\",\n",
    "        \"2025-06-04 13:00\", \"2025-06-04 17:00\", \"2025-06-05 19:00\", \"2025-06-05 21:15\"\n",
    "    ],\n",
    "    \"purchase_amount\": [100, 150, 80, 200, 50, 90, 120, 60, 130, 170],\n",
    "    \"product\": [\"A\",\"B\",\"A\",\"C\",\"B\",\"A\",\"C\",\"B\",\"A\",\"C\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"purchase_datetime\"] = pd.to_datetime(df[\"purchase_datetime\"])\n",
    "\n",
    "# Tool untuk analisis data manual\n",
    "def sales_detailed_analysis(query: str) -> str:\n",
    "    avg_purchase_gender = df.groupby(\"gender\")[\"purchase_amount\"].mean()\n",
    "    purchase_count_by_hour = df.groupby(df[\"purchase_datetime\"].dt.hour).size()\n",
    "    peak_hour = purchase_count_by_hour.idxmax()\n",
    "    gender_peak_hour = df[df[\"purchase_datetime\"].dt.hour == peak_hour].groupby(\"gender\").size()\n",
    "    most_active_gender = gender_peak_hour.idxmax()\n",
    "\n",
    "    result = (\n",
    "        f\"Rata-rata pembelian berdasarkan jenis kelamin:\\n{avg_purchase_gender.to_string()}\\n\\n\"\n",
    "        f\"Jumlah pembelian per jam:\\n{purchase_count_by_hour.to_string()}\\n\\n\"\n",
    "        f\"Jam sibuk: {peak_hour}:00\\n\"\n",
    "        f\"Jenis kelamin paling aktif di jam sibuk: {most_active_gender}\"\n",
    "    )\n",
    "    return result\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"SalesDetailedAnalyzer\",\n",
    "        func=sales_detailed_analysis,\n",
    "        description=\"Analisis data penjualan secara detail dan spesifik.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Berikut adalah hasil analisis data penjualan:\n",
    "\n",
    "{analysis}\n",
    "\n",
    "Tolong jelaskan hasil analisis ini dengan bahasa yang mudah dimengerti,\n",
    "dan berikan saran strategis yang relevan untuk bisnis berdasarkan hasil tersebut.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"analysis\"], template=prompt_template)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "#  hasil analisis\n",
    "analysis_result = agent.run(\"Lakukan analisis detail penjualan.\")\n",
    "\n",
    "#LLM untuk penjelasan & saran\n",
    "response = llm_chain.run(analysis=analysis_result)\n",
    "\n",
    "print(\"Hasil Analisis dan Saran dari AI:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Produk ini sangat bagus dan memuaskan!\n",
      "Sentimen: Kalimat tersebut memiliki sentimen positif. Ungkapan \"sangat bagus\" dan \"memuaskan\" menunjukkan kepuasan dan apresiasi terhadap produk. Secara keseluruhan, kalimat ini mencerminkan pengalaman yang baik dengan produk tersebut.\n",
      "----------------------------------------\n",
      "Review: Pelayanan yang buruk, saya kecewa sekali.\n",
      "Sentimen: Kalimat tersebut mengandung sentimen negatif. Ungkapan \"pelayanan yang buruk\" menunjukkan ketidakpuasan, dan frasa \"saya kecewa sekali\" memperkuat perasaan negatif tersebut. Secara keseluruhan, kalimat ini mencerminkan kekecewaan dan ketidakpuasan terhadap suatu layanan.\n",
      "----------------------------------------\n",
      "Review: Barang sampai tepat waktu tapi kualitas biasa saja.\n",
      "Sentimen: Sentimen dari kalimat tersebut cenderung netral cenderung negatif. Poin positifnya adalah barang yang sampai tepat waktu, tetapi diimbangi dengan penilaian negatif mengenai kualitas yang dianggap biasa saja. Secara keseluruhan, kalimat ini menyiratkan ketidakpuasan terhadap kualitas produk.\n",
      "----------------------------------------\n",
      "Review: Harga mahal tapi kualitas sesuai.\n",
      "Sentimen: Kalimat \"Harga mahal tapi kualitas sesuai.\" mengandung sentimen campuran. \n",
      "\n",
      "- **Aspek positif**: \"kualitas sesuai\" menunjukkan bahwa konsumen merasa puas dengan kualitas produk.\n",
      "- **Aspek negatif**: \"harga mahal\" menunjukkan ketidakpuasan terkait harga yang tinggi.\n",
      "\n",
      "Secara keseluruhan, kalimat ini mencerminkan perasaan yang ambigu, di mana ada pujian terhadap kualitas tetapi juga keluhan mengenai harga. Sentimen dapat dianggap netral atau mixed, tergantung pada konteks lebih lanjut dari pengalaman pengguna.\n",
      "----------------------------------------\n",
      "Review: Saya suka desainnya tapi ukurannya terlalu kecil.\n",
      "Sentimen: Kalimat tersebut memiliki sentimen campuran. Di satu sisi, ungkapan \"Saya suka desainnya\" menunjukkan sentimen positif terhadap desain. Namun, di sisi lain, pernyataan \"ukurannya terlalu kecil\" mengindikasikan ketidakpuasan, yang merupakan sentimen negatif. Secara keseluruhan, meskipun ada elemen positif, terdapat elemen ketidakpuasan yang cukup signifikan, sehingga bisa dianggap sebagai sentimen netral sampai negatif.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# client OpenAI \n",
    "client = OpenAI()\n",
    "\n",
    "def analisis_sentimen(teks):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Kamu adalah analis sentimen yang jujur dan akurat.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Analisa sentimen dari kalimat berikut:\\n\\n{teks}\"}\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    contoh_review = [\n",
    "        \"Produk ini sangat bagus dan memuaskan!\",\n",
    "        \"Pelayanan yang buruk, saya kecewa sekali.\",\n",
    "        \"Barang sampai tepat waktu tapi kualitas biasa saja.\",\n",
    "        \"Harga mahal tapi kualitas sesuai.\",\n",
    "        \"Saya suka desainnya tapi ukurannya terlalu kecil.\"\n",
    "    ]\n",
    "\n",
    "    for review in contoh_review:\n",
    "        hasil = analisis_sentimen(review)\n",
    "        print(f\"Review: {review}\")\n",
    "        print(f\"Sentimen: {hasil}\")\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"review\": [\n",
    "        \"Produk ini sangat bagus dan memuaskan!\",\n",
    "        \"Pelayanan yang buruk, saya kecewa sekali.\",\n",
    "        \"Barang sampai tepat waktu tapi kualitas biasa saja.\",\n",
    "        \"Harga mahal tapi kualitas sesuai.\",\n",
    "        \"Saya suka desainnya tapi ukurannya terlalu kecil.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"reviews.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memproses baris 1/5: Positif\n",
      "Memproses baris 2/5: Negatif\n",
      "Memproses baris 3/5: Netral\n",
      "Memproses baris 4/5: Netral\n",
      "Memproses baris 5/5: Netral\n",
      "Hasil analisis disimpan di reviews_sentimen.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Inisialisasi client OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def analisis_sentimen(teks):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Kamu adalah analis sentimen yang hanya menjawab dengan kata Positif, Negatif, atau Netral tanpa penjelasan.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Analisa sentimen dari kalimat berikut:\\n\\n{teks}\"}\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def proses_batch(input_csv, output_csv, kolom_teks):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    hasil_sentimen = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        teks = row[kolom_teks]\n",
    "        sentimen = analisis_sentimen(teks)\n",
    "        hasil_sentimen.append(sentimen)\n",
    "        print(f\"Memproses baris {i+1}/{len(df)}: {sentimen}\")\n",
    "        time.sleep(1)  # Delay supaya tidak kena rate limit\n",
    "\n",
    "    df['sentimen'] = hasil_sentimen\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Hasil analisis disimpan di {output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"reviews.csv\"     # File CSV input berisi kolom teks review\n",
    "    output_file = \"reviews_sentimen.csv\"\n",
    "    kolom_teks = \"review\"          # Nama kolom teks di CSV\n",
    "\n",
    "    proses_batch(input_file, output_file, kolom_teks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Inisialisasi client OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def analisis_sentimen(teks):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Kamu adalah analis sentimen yang hanya menjawab dengan kata Positif, Negatif, atau Netral tanpa penjelasan.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Analisa sentimen dari kalimat berikut:\\n\\n{teks}\"}\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dari fungsi analisis_sentimen:\n",
      "Negatif\n"
     ]
    }
   ],
   "source": [
    "hasil = analisis_sentimen(\"Saya sangat kecewa dengan layanan ini.\")\n",
    "print(\"Output dari fungsi analisis_sentimen:\")\n",
    "print(hasil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proses_batch(input_csv, output_csv, kolom_teks):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    hasil_sentimen = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        teks = row[kolom_teks]\n",
    "        sentimen = analisis_sentimen(teks)\n",
    "        hasil_sentimen.append(sentimen)\n",
    "        print(f\"Memproses baris {i+1}/{len(df)}: {sentimen}\")\n",
    "        time.sleep(1)  \n",
    "\n",
    "    df['sentimen'] = hasil_sentimen\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Hasil analisis disimpan di {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_file = \"reviews.csv\"     \n",
    "    output_file = \"reviews_sentimen.csv\"\n",
    "    kolom_teks = \"review\"         \n",
    "    proses_batch(input_file, output_file, kolom_teks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_experimental in c:\\users\\asus\\miniconda3\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain_experimental) (0.3.26)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain_experimental) (0.3.66)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.12.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.1.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (4.13.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.11.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.8)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.2.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14916\\3379355741.py:18: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  hasil = agent.run(pertanyaan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the player with the highest number of goals.\n",
      "Action: python_repl_ast\n",
      "Action Input: df.loc[df['Goals'].idxmax()]\u001b[0m\u001b[36;1m\u001b[1;3mPlayer Name        Mohamed Salah\n",
      "Club                   Liverpool\n",
      "Nationality                Egypt\n",
      "Position                     MID\n",
      "Appearances                   38\n",
      "Minutes                     3377\n",
      "Goals                         29\n",
      "Assists                       18\n",
      "Shots                        130\n",
      "Shots On Target               22\n",
      "Name: 324, dtype: object\u001b[0m\u001b[32;1m\u001b[1;3mI need to extract the player name, club, and number of goals from this result.\n",
      "Action: python_repl_ast\n",
      "Action Input: df.loc[df['Goals'].idxmax()]['Player Name'], df.loc[df['Goals'].idxmax()]['Club'], df.loc[df['Goals'].idxmax()]['Goals']\u001b[0m\u001b[36;1m\u001b[1;3m('Mohamed Salah', 'Liverpool', np.int64(29))\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: Mohamed Salah, Liverpool, 29 goals.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Mohamed Salah, Liverpool, 29 goals.\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain.llms import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Baca data\n",
    "df = pd.read_csv(\"player_stats.csv\")  \n",
    "\n",
    "# Inisialisasi Agent dengan izin eksekusi kode\n",
    "agent = create_pandas_dataframe_agent(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    df=df,\n",
    "    verbose=True,\n",
    "    allow_dangerous_code=True \n",
    ")\n",
    "\n",
    "# Ajukan pertanyaan\n",
    "pertanyaan = \"Siapa pemain dengan gol terbanyak? Berikan nama, klub, dan jumlah golnya.\"\n",
    "hasil = agent.run(pertanyaan)\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Scorer:   Player Name      Club  Goals\n",
      "Mohamed Salah Liverpool     29\n",
      "\n",
      "Most Minutes Played:\n",
      "   Player Name              Club  Minutes\n",
      "     Matz Sels Nottingham Forest     3420\n",
      "Dean Henderson    Crystal Palace     3420\n",
      "    David Raya           Arsenal     3420\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"player_stats.csv\")\n",
    "\n",
    "# 1. Pemain dengan gol terbanyak\n",
    "top_scorer = df[df[\"Goals\"] == df[\"Goals\"].max()]\n",
    "print(\"Top Scorer:\", top_scorer[[\"Player Name\", \"Club\", \"Goals\"]].to_string(index=False))\n",
    "\n",
    "# 2. Pemain dengan menit bermain terbanyak (top 3)\n",
    "most_minutes = df.sort_values(\"Minutes\", ascending=False).head(3)\n",
    "print(\"\\nMost Minutes Played:\")\n",
    "print(most_minutes[[\"Player Name\", \"Club\", \"Minutes\"]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mohamed Salah', 'Liverpool', np.int64(29))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Goals'].idxmax()]['Player Name'], df.loc[df['Goals'].idxmax()]['Club'], df.loc[df['Goals'].idxmax()]['Goals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\asus\\miniconda3\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in c:\\users\\asus\\miniconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\asus\\miniconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\miniconda3\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\miniconda3\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\miniconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\miniconda3\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love this product! It's amazing.\n",
      "Sentimen: POSITIVE (Score: 0.9999)\n",
      "\n",
      "Text: The service was terrible and slow.\n",
      "Sentimen: NEGATIVE (Score: 0.9996)\n",
      "\n",
      "Text: It's okay, but could be better.\n",
      "Sentimen: POSITIVE (Score: 0.9623)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Inisialisasi pipeline analisis sentimen\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"  # Model default untuk English\n",
    ")\n",
    "\n",
    "# Contoh teks untuk dianalisis\n",
    "texts = [\n",
    "    \"I love this product! It's amazing.\",\n",
    "    \"The service was terrible and slow.\",\n",
    "    \"It's okay, but could be better.\"\n",
    "]\n",
    "\n",
    "# Analisis sentimen\n",
    "results = sentiment_analyzer(texts)\n",
    "\n",
    "# Tampilkan hasil\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentimen: {result['label']} (Score: {result['score']:.4f})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenezer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [40141, 43011, 15117, 72, 11, 61693, 75095, 277, 30]\n",
      "Jumlah Token: 9\n",
      "Teks Asli: Selamat pagi, apa kabar?\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "# Contoh teks\n",
    "text = \"Selamat pagi, apa kabar?\"\n",
    "\n",
    "token_ids = encoder.encode(text)\n",
    "print(\"Token IDs:\", token_ids)\n",
    "print(\"Jumlah Token:\", len(token_ids))\n",
    "\n",
    "print(\"Teks Asli:\", encoder.decode(token_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
